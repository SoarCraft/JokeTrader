{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method(\"forkserver\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from typing import Any, Dict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pybit.unified_trading import HTTP\n",
    "from IPython.display import display\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecMonitor, SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import (\n",
    "    EvalCallback,\n",
    "    StopTrainingOnNoModelImprovement,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40929d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _datetime_to_ms(dt: str | datetime) -> int:\n",
    "    ts = pd.Timestamp(dt, tz=\"UTC\") if isinstance(dt, str) else pd.Timestamp(dt).tz_convert(\"UTC\")\n",
    "    return int(ts.timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_ohlcv_minute(session: HTTP, symbol: str, start_ms: int, end_ms: int, limit: int = 1000) -> pd.DataFrame:\n",
    "    rows: list[list] = []\n",
    "    cur = start_ms\n",
    "    step_ms = 60_000 # 1 minute in milliseconds\n",
    "    total_minutes = (end_ms - start_ms) // step_ms\n",
    "\n",
    "    with tqdm(total=total_minutes, desc=f\"Fetching {symbol} OHLCV\") as pbar:\n",
    "        while cur < end_ms:\n",
    "            start_time_current_call = cur\n",
    "            resp = session.get_kline(category=\"linear\", symbol=symbol, interval=\"1\", start=cur, limit=limit)\n",
    "            data = resp[\"result\"][\"list\"]\n",
    "            if not data:\n",
    "                # If no data is returned, assume we reached the end for the requested period\n",
    "                # Update progress bar to reflect the remaining time as processed\n",
    "                remaining_minutes = (end_ms - cur) // step_ms\n",
    "                pbar.update(remaining_minutes)\n",
    "                break\n",
    "\n",
    "            rows.extend(data)\n",
    "            last_ts = int(data[-1][0])\n",
    "\n",
    "            # Calculate minutes fetched in this call and update progress bar\n",
    "            minutes_fetched = (last_ts - start_time_current_call + step_ms) // step_ms\n",
    "            pbar.update(minutes_fetched)\n",
    "\n",
    "            # Set cursor for the next iteration\n",
    "            cur = last_ts + step_ms\n",
    "\n",
    "            # Ensure progress doesn't exceed total if API returns data beyond end_ms\n",
    "            if pbar.n > total_minutes:\n",
    "                 pbar.n = total_minutes\n",
    "                 pbar.refresh()\n",
    "\n",
    "        # Ensure the progress bar completes if the loop finishes early\n",
    "        if pbar.n < total_minutes:\n",
    "             pbar.update(total_minutes - pbar.n)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"startTime\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"turnover\"])\n",
    "    df[\"startTime\"] = pd.to_datetime(df[\"startTime\"], unit=\"ms\", utc=True)\n",
    "    df.set_index(\"startTime\", inplace=True)\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms)\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "    df = df.astype(float)[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_long_short_ratio(session: HTTP, symbol: str, start_ms: int, end_ms: int) -> pd.Series:\n",
    "    rows = []\n",
    "    limit = 500\n",
    "    interval_ms = 5 * 60_000 # 5 minutes in milliseconds\n",
    "    total_intervals = (end_ms - start_ms) // interval_ms\n",
    "    last_fetched_ts = start_ms\n",
    "\n",
    "    with tqdm(total=total_intervals, desc=f\"Fetching {symbol} Long/Short Ratio\") as pbar:\n",
    "        while True:\n",
    "            start_time_current_call = last_fetched_ts\n",
    "            try:\n",
    "                resp = session.get_long_short_ratio(\n",
    "                    category=\"linear\",\n",
    "                    symbol=symbol,\n",
    "                    period=\"5min\",\n",
    "                    startTime=start_time_current_call, # Use last fetched timestamp to avoid overlap issues\n",
    "                    endTime=end_ms,\n",
    "                    limit=limit\n",
    "                )\n",
    "                data = resp[\"result\"][\"list\"]\n",
    "                if not data:\n",
    "                    # No more data in the range for this call\n",
    "                    remaining_intervals = max(0, (end_ms - last_fetched_ts) // interval_ms)\n",
    "                    pbar.update(remaining_intervals)\n",
    "                    break # Exit loop if no data is returned\n",
    "\n",
    "                rows.extend(data)\n",
    "                current_last_ts = int(data[-1][\"timestamp\"])\n",
    "\n",
    "                # Calculate intervals fetched based on time covered\n",
    "                intervals_fetched = max(0, (current_last_ts - last_fetched_ts) // interval_ms)\n",
    "                # Add 1 interval for the last timestamp itself if it wasn't fully covered by the division\n",
    "                if (current_last_ts - last_fetched_ts) % interval_ms > 0 or intervals_fetched == 0:\n",
    "                     intervals_fetched += 1\n",
    "\n",
    "\n",
    "                pbar.update(intervals_fetched)\n",
    "                last_fetched_ts = current_last_ts + interval_ms # Set start for next potential fetch\n",
    "\n",
    "                # Check if we have fetched data beyond the requested end_ms\n",
    "                if last_fetched_ts >= end_ms:\n",
    "                     # Ensure progress bar completes if we fetched up to or beyond end_ms\n",
    "                     if pbar.n < total_intervals:\n",
    "                         pbar.update(total_intervals - pbar.n)\n",
    "                     break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                # Update progress bar to reflect the assumed end if an error occurs\n",
    "                if pbar.n < total_intervals:\n",
    "                    pbar.update(total_intervals - pbar.n)\n",
    "                break # Exit loop on error\n",
    "\n",
    "        # Ensure the progress bar completes fully if the loop finishes early\n",
    "        if pbar.n < total_intervals:\n",
    "             pbar.update(total_intervals - pbar.n)\n",
    "\n",
    "\n",
    "    if not rows:\n",
    "        # Return an empty series with the correct dtype if no data was fetched\n",
    "        return pd.Series(dtype=float, name=\"ls_ratio\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"].astype(int), unit=\"ms\", utc=True)\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "    df = df.sort_index()\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms)\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "    # Remove potential duplicates from overlapping API calls if cursor wasn't effective\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name=\"ls_ratio\")\n",
    "\n",
    "    df[[\"buyRatio\", \"sellRatio\"]] = df[[\"buyRatio\", \"sellRatio\"]].astype(float)\n",
    "    # Avoid division by zero if both buyRatio and sellRatio are 0\n",
    "    total_ratio = df[\"buyRatio\"] + df[\"sellRatio\"]\n",
    "    ls_ratio = df[\"buyRatio\"].divide(total_ratio).fillna(0.5) # Fill NaN with 0.5 (neutral) or 0\n",
    "\n",
    "    # Resample to 1 minute and forward fill\n",
    "    ls_ratio = ls_ratio.resample(\"1min\").ffill()\n",
    "    # Ensure the resampled series covers the full requested range, padding with ffill/bfill\n",
    "    full_range_index = pd.date_range(start=pd.to_datetime(start_ms, unit='ms', utc=True),\n",
    "                                     end=pd.to_datetime(end_ms - 1, unit='ms', utc=True), # end is exclusive\n",
    "                                     freq='1min')\n",
    "    ls_ratio = ls_ratio.reindex(full_range_index).ffill().bfill() # Forward fill then backfill NaNs\n",
    "\n",
    "    return ls_ratio.rename(\"ls_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60251003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_funding_rate(session: HTTP, symbol: str, start_ms: int, end_ms: int) -> pd.Series:\n",
    "    rows = []\n",
    "    cursor = None\n",
    "    limit = 200 # Max limit for funding rate history\n",
    "    # Estimate total intervals for progress bar (funding typically every 8 hours)\n",
    "    interval_ms = 8 * 60 * 60_000\n",
    "    total_intervals = max(1, (end_ms - start_ms) // interval_ms)\n",
    "    last_fetched_ts = start_ms # Track the timestamp of the last fetched record for progress update\n",
    "\n",
    "    with tqdm(total=total_intervals, desc=f\"Fetching {symbol} Funding Rate\") as pbar:\n",
    "        while True:\n",
    "            try:\n",
    "                resp = session.get_funding_rate_history(\n",
    "                    category=\"linear\",\n",
    "                    symbol=symbol,\n",
    "                    # Rely primarily on cursor for pagination, filter by time later\n",
    "                    limit=limit,\n",
    "                    cursor=cursor\n",
    "                )\n",
    "\n",
    "                data = resp[\"result\"][\"list\"]\n",
    "                if not data:\n",
    "                    # No more data from API for this cursor\n",
    "                    if pbar.n < total_intervals:\n",
    "                        pbar.update(total_intervals - pbar.n) # Complete the bar\n",
    "                    break\n",
    "\n",
    "                rows.extend(data)\n",
    "                current_last_ts = int(data[-1][\"fundingRateTimestamp\"])\n",
    "\n",
    "                # Update progress based on time covered since last fetch\n",
    "                if current_last_ts > last_fetched_ts:\n",
    "                    intervals_covered = (current_last_ts - last_fetched_ts) // interval_ms\n",
    "                    # Ensure at least 1 interval is credited if any time passed and data received\n",
    "                    if intervals_covered == 0 and current_last_ts > last_fetched_ts:\n",
    "                         intervals_covered = 1\n",
    "                    # Cap update to not exceed total\n",
    "                    update_amount = min(intervals_covered, total_intervals - pbar.n)\n",
    "                    if update_amount > 0:\n",
    "                        pbar.update(update_amount)\n",
    "                    last_fetched_ts = current_last_ts # Update last fetched timestamp\n",
    "\n",
    "                cursor = resp[\"result\"].get(\"nextPageCursor\")\n",
    "                if not cursor:\n",
    "                    # No next page cursor means we are done fetching\n",
    "                    if pbar.n < total_intervals:\n",
    "                        pbar.update(total_intervals - pbar.n) # Complete the bar\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during funding rate fetch: {e}\")\n",
    "                # Update progress bar to reflect the assumed end if an error occurs\n",
    "                if pbar.n < total_intervals:\n",
    "                    pbar.update(total_intervals - pbar.n)\n",
    "                break # Exit loop on error\n",
    "\n",
    "        # Ensure the progress bar completes fully if the loop finished early\n",
    "        if pbar.n < total_intervals:\n",
    "             pbar.update(total_intervals - pbar.n)\n",
    "\n",
    "    if not rows:\n",
    "        # Return an empty series with the correct dtype and name if no data was fetched\n",
    "        return pd.Series(dtype=float, name=\"fundingRate\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"fundingRateTimestamp\"] = pd.to_datetime(df[\"fundingRateTimestamp\"].astype(int), unit=\"ms\", utc=True)\n",
    "    df.set_index(\"fundingRateTimestamp\", inplace=True)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms) AFTER collecting all data\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name=\"fundingRate\")\n",
    "\n",
    "    # Remove potential duplicates just in case (e.g., overlapping calls if cursor logic had issues)\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    df[\"fundingRate\"] = df[\"fundingRate\"].astype(float)\n",
    "\n",
    "    # Resample to 1 minute and interpolate linearly\n",
    "    funding_series = df[\"fundingRate\"].resample(\"1min\").interpolate(method='linear')\n",
    "\n",
    "    # Ensure the resampled series covers the full requested range, padding with ffill/bfill\n",
    "    full_range_index = pd.date_range(start=pd.to_datetime(start_ms, unit='ms', utc=True),\n",
    "                                     end=pd.to_datetime(end_ms - 1, unit='ms', utc=True), # end is exclusive\n",
    "                                     freq='1min')\n",
    "    # Reindex to the full range, then fill any remaining NaNs at the beginning/end\n",
    "    # Interpolation handles NaNs between points, ffill/bfill handle edges.\n",
    "    funding_series = funding_series.reindex(full_range_index).ffill().bfill()\n",
    "\n",
    "    return funding_series.rename(\"fundingRate\") # Ensure series name is set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bybit_data(\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    start: str | datetime = \"2025-03-01 00:00:00\",\n",
    "    end: str | datetime = \"2025-04-01 00:00:00\",\n",
    "    save_csv: bool = False,\n",
    "    out_dir: str | Path = \"data\",\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    import numpy as np\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    npz_path = out / f\"{symbol}_bybit_data.npz\"\n",
    "\n",
    "    # ---------- Try loading from .npz ----------\n",
    "    if npz_path.exists():\n",
    "        print(f\"Loading data from NPZ file: {npz_path}\")\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "\n",
    "        ohlcv_cols = data[\"ohlcv_columns\"]\n",
    "        ohlcv_idx = pd.to_datetime(data[\"ohlcv_index\"])\n",
    "        ohlcv = pd.DataFrame(data[\"ohlcv_values\"], columns=ohlcv_cols)\n",
    "        ohlcv.index = ohlcv_idx\n",
    "        ohlcv.index.name = \"startTime\"\n",
    "        ohlcv = ohlcv.astype(float).asfreq(\"1min\")\n",
    "\n",
    "        lsr = pd.Series(data[\"lsr_values\"], index=pd.to_datetime(data[\"lsr_index\"]), name=\"ls_ratio\").asfreq(\"1min\")\n",
    "        funding = pd.Series(data[\"funding_values\"], index=pd.to_datetime(data[\"funding_index\"]), name=\"fundingRate\").asfreq(\"1min\")\n",
    "\n",
    "        return ohlcv, lsr, funding\n",
    "\n",
    "    # ---------- Fetch from API ----------\n",
    "    print(\"Fetching data from Bybit API...\")\n",
    "    session = HTTP(testnet=False)\n",
    "    start_ms, end_ms = _datetime_to_ms(start), _datetime_to_ms(end)\n",
    "    ohlcv = _fetch_ohlcv_minute(session, symbol, start_ms, end_ms)\n",
    "    lsr = _fetch_long_short_ratio(session, symbol, start_ms, end_ms)\n",
    "    funding = _fetch_funding_rate(session, symbol, start_ms, end_ms)\n",
    "\n",
    "    # ---------- Save to npz ----------\n",
    "    print(f\"Saving data to NPZ file: {npz_path}\")\n",
    "    np.savez_compressed(\n",
    "        npz_path,\n",
    "        ohlcv_values=ohlcv.to_numpy(),\n",
    "        ohlcv_columns=np.array(ohlcv.columns),\n",
    "        ohlcv_index=ohlcv.index.astype(np.int64),\n",
    "        lsr_values=lsr.to_numpy(),\n",
    "        lsr_index=lsr.index.astype(np.int64),\n",
    "        funding_values=funding.to_numpy(),\n",
    "        funding_index=funding.index.astype(np.int64),\n",
    "    )\n",
    "\n",
    "    # ---------- Optionally save to CSV ----------\n",
    "    if save_csv:\n",
    "        print(f\"Also saving CSV to {out_dir}...\")\n",
    "        ohlcv.to_csv(out / f\"{symbol}_ohlcv_1min.csv\")\n",
    "        lsr.to_csv(out / f\"{symbol}_long_short_ratio.csv\", header=True)\n",
    "        funding.to_csv(out / f\"{symbol}_funding_rate.csv\", header=True)\n",
    "\n",
    "    return ohlcv, lsr, funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69867a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df, ls_series, funding_series = fetch_bybit_data(save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OHLCV Data:\")\n",
    "display(ohlcv_df.info())\n",
    "\n",
    "print(\"\\nLong/Short Ratio Data:\")\n",
    "display(ls_series.info())\n",
    "\n",
    "print(\"\\nFunding Rate Data:\")\n",
    "display(funding_series.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(series: pd.Series, period: int) -> pd.Series:\n",
    "    return series.rolling(window=period, min_periods=period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(series: pd.Series, period: int) -> pd.Series:\n",
    "    return series.ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15047e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(df: pd.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:\n",
    "    ema_fast = ema(df[\"close\"], fast)\n",
    "    ema_slow = ema(df[\"close\"], slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = ema(macd_line, signal)\n",
    "    hist = macd_line - signal_line\n",
    "    return pd.DataFrame({\"macd\": macd_line, \"macd_signal\": signal_line, \"macd_hist\": hist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0.0)).rolling(period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0.0)).rolling(period).mean()\n",
    "    rs = gain / (loss + 1e-12)\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connors_rsi(df: pd.DataFrame, rsi_period: int = 3, streak_rsi_period: int = 2, pct_rank_period: int = 100) -> pd.Series:\n",
    "    close = df[\"close\"]\n",
    "    # (1) ä»·æ ¼ RSI\n",
    "    rsi_cl = rsi(close, rsi_period)\n",
    "    # (2) è¿æ¶¨/è·Œå¤©æ•°\n",
    "    streak = np.sign(close.diff()).fillna(0)\n",
    "    streak = streak.groupby((streak != streak.shift()).cumsum()).cumsum()\n",
    "    rsi_streak = rsi(streak, streak_rsi_period)\n",
    "    # (3) å½“æ—¥æ¶¨è·Œå¹…åœ¨è¿‡å» n æ—¥ç™¾åˆ†ä½\n",
    "    pct_change = close.pct_change().fillna(0)\n",
    "    pct_rank = pct_change.rolling(pct_rank_period).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100, raw=False)\n",
    "    # CRSI = ä¸Šè¿°ä¸‰è€…å¹³å‡\n",
    "    crsi = (rsi_cl + rsi_streak + pct_rank) / 3.0\n",
    "    return crsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_resistance(df: pd.DataFrame, lookback: int = 60) -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"è¿”å› (support, resistance) æ”¯æ’‘ / å‹åŠ›ä½\"\"\"\n",
    "    rolling_low = df[\"low\"].rolling(lookback).min()\n",
    "    rolling_high = df[\"high\"].rolling(lookback).max()\n",
    "    return rolling_low, rolling_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daff948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitcoinFuturesEnv(gym.Env):\n",
    "    \"\"\"BTC æ°¸ç»­åˆçº¦ç¯å¢ƒï¼ˆçº¿æ€§ã€USDT è®¡ä»·ï¼‰\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ohlcv: pd.DataFrame,\n",
    "        long_short_ratio: pd.Series,\n",
    "        funding_rate: pd.Series,\n",
    "        window_size: int = 60,\n",
    "        initial_balance: float = 1_000_000.0,\n",
    "        fee_rate: float = 0.00044,\n",
    "        leverage: float = 10.0,\n",
    "        maintenance_margin_ratio: float = 0.005,\n",
    "        random_start: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # è¾“å…¥é•¿åº¦æ£€æŸ¥\n",
    "        assert ohlcv.index.freq == \"1min\", \\\n",
    "            f\"OHLCV å¿…é¡»æ˜¯ 1 åˆ†é’Ÿé¢‘ç‡çš„ DataFrame, å½“å‰ freq={ohlcv.index.freq}\"\n",
    "        assert len(ohlcv) == len(long_short_ratio) == len(funding_rate), \\\n",
    "            \"OHLCVã€long_short_ratio å’Œ funding_rate å¿…é¡»ç­‰é•¿\"\n",
    "        # æŒ‡æ ‡çª—å£å¤§å°æ£€æŸ¥\n",
    "        assert window_size >= 50, f\"window_size å¿…é¡» >= {50} æ‰èƒ½è®¡ç®—æŠ€æœ¯æŒ‡æ ‡\"\n",
    "\n",
    "        self.ohlcv = ohlcv.reset_index(drop=False)\n",
    "        self.long_short_ratio = long_short_ratio.reset_index(drop=True)\n",
    "        self.funding_rate = funding_rate.reset_index(drop=True)\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.fee_rate = fee_rate\n",
    "        self.leverage_setting = leverage\n",
    "        self.maintenance_margin_ratio = maintenance_margin_ratio\n",
    "        self.random_start = random_start\n",
    "        # self.max_episode_minutes = 21 * 24 * 60  # days in minutes\n",
    "        self._step_counter = 0\n",
    "\n",
    "        # ===== é¢„å…ˆè®¡ç®—æŠ€æœ¯æŒ‡æ ‡ =====\n",
    "        self._precompute_indicators()\n",
    "\n",
    "        # ===== Gym spaces =====\n",
    "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        obs_dim = (\n",
    "            window_size * 14  # OHLC + Volume + 9ä¸ªæŠ€æœ¯æŒ‡æ ‡\n",
    "            + 5  # position info & å¯ç”¨ä½™é¢ etc.\n",
    "            + 2  # èµ„é‡‘è´¹ç‡å’Œå¤šç©ºæ¯”ä¾‹\n",
    "        )\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        # å†…éƒ¨çŠ¶æ€\n",
    "        self._reset_account()\n",
    "        self._ptr: int = self.window_size  # æ•°æ®æŒ‡é’ˆ\n",
    "\n",
    "    def _precompute_indicators(self):\n",
    "        \"\"\"ä¸€æ¬¡æ€§è®¡ç®—å¹¶å­˜å‚¨æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡ï¼Œå¡«å……ç¼ºå¤±å€¼\"\"\"\n",
    "        df = self.ohlcv.copy()\n",
    "        # è®¡ç®—æŒ‡æ ‡\n",
    "        df['sma_fast'] = sma(df['close'], 20)\n",
    "        df['sma_slow'] = sma(df['close'], 50)\n",
    "        df['ema'] = ema(df['close'], 20)\n",
    "        macd_df = macd(df)\n",
    "        df = pd.concat([df, macd_df], axis=1)\n",
    "        df['crsi'] = connors_rsi(df)\n",
    "        support, resistance = support_resistance(df)\n",
    "        df['support'] = support\n",
    "        df['resistance'] = resistance\n",
    "\n",
    "        features = [\n",
    "            'open','high','low','close','volume',\n",
    "            'sma_fast','sma_slow','ema',\n",
    "            'macd','macd_signal','macd_hist',\n",
    "            'crsi','support','resistance'\n",
    "        ]\n",
    "        df = df[features].ffill().fillna(0.0)\n",
    "        # è½¬ä¸º NumPy åŠ é€Ÿåˆ‡ç‰‡\n",
    "        self.tech_all = df.to_numpy(dtype=np.float32)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # é‡ç½® / æ­¥è¿›\n",
    "    # ---------------------------------\n",
    "    def reset(self, *, seed: int | None = None):\n",
    "        super().reset(seed=seed)\n",
    "        self._reset_account()\n",
    "        self._step_counter = 0\n",
    "        if self.random_start:\n",
    "            self._ptr = self.np_random.integers(self.window_size, len(self.tech_all) / 2)\n",
    "        else:\n",
    "            self._ptr = self.window_size\n",
    "        obs = self._get_observation()\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"æ‰§è¡Œä¸€æ­¥ï¼Œaction âˆˆ [-1,1].\"\"\"\n",
    "        action_val = float(action[0])\n",
    "        price = self._current_price()\n",
    "\n",
    "        # === å¼ºå¹³æ£€æŸ¥ï¼ˆå…ˆäºèµ„é‡‘è´¹ï¼‰ ===\n",
    "        self._check_liquidation(price)\n",
    "        # === èµ„é‡‘è´¹å¤„ç† ===\n",
    "        self._apply_funding(price)\n",
    "\n",
    "        # === è§£æåŠ¨ä½œ ===\n",
    "        if abs(action_val) > 0.01:\n",
    "            if self.position_size == 0:\n",
    "                # å¼€æ–°ä»“\n",
    "                self._open_position(action_val, price)\n",
    "            else:\n",
    "                same_direction = (self.position_size > 0 and action_val > 0) or (\n",
    "                    self.position_size < 0 and action_val < 0\n",
    "                )\n",
    "                if same_direction:\n",
    "                    # åŠ ä»“\n",
    "                    self._add_position(action_val, price)\n",
    "                else:\n",
    "                    # å‡ä»“æˆ–åå‘ â†’ å…ˆå¹³éƒ¨åˆ† / å…¨å¹³\n",
    "                    self._reduce_or_close(action_val, price)\n",
    "\n",
    "        # === æ—¶é—´å‘å‰æ¨è¿› ===\n",
    "        self._ptr += 1\n",
    "        self._step_counter += 1\n",
    "\n",
    "        # åˆ°æ•°æ®æœ«å°¾ç®—ä½œtruncateï¼ˆæ—¶é—´ç”¨å°½ï¼‰\n",
    "        # truncated = self._ptr >= len(self.tech_all) - 1 or self._step_counter >= self.max_episode_minutes\n",
    "        truncated = self._ptr >= len(self.tech_all) - 1\n",
    "        # ä½™é¢ä¸ºé›¶æˆ–è´Ÿæ•°ç®—ä½œterminatedï¼ˆç ´äº§ï¼‰\n",
    "        terminated = self.balance <= 0\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        reward = self.realized_pnl + (self._unrealized_pnl(price) - self._last_unrealized_pnl)  # å·®åˆ†å¥–åŠ±\n",
    "        self._last_unrealized_pnl = self._unrealized_pnl(price)\n",
    "        self.realized_pnl = 0.0  # æ¸…é›¶ï¼Œé¿å…ä¸‹è½®é‡å¤\n",
    "\n",
    "        info = (\n",
    "            {\n",
    "                \"equity\": self.balance + self._unrealized_pnl(price),\n",
    "                \"position_size\": self.position_size,\n",
    "                \"entry_price\": self.entry_price,\n",
    "                \"unrealized_pnl\": self._unrealized_pnl(price),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if terminated:\n",
    "            info[\"termination_reason\"] = \"bankrupt\"\n",
    "        elif truncated:\n",
    "            info[\"termination_reason\"] = \"time_limit\"\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ---------------------------------\n",
    "    # è´¦æˆ·é€»è¾‘\n",
    "    # ---------------------------------\n",
    "    def _reset_account(self):\n",
    "        self._last_unrealized_pnl = 0.0  # åˆå§‹åŒ–è¿½è¸ªæµ®åŠ¨æ”¶ç›Šå·®åˆ†\n",
    "        self.balance: float = self.initial_balance  # å¯ç”¨ä½™é¢ / Equity\n",
    "        self.position_size: float = 0.0  # >0 long <0 short (å¼ æ•° BTC)\n",
    "        self.entry_price: float = 0.0\n",
    "        self.realized_pnl: float = 0.0\n",
    "\n",
    "    def _apply_fee(self, notional: float):\n",
    "        fee = abs(notional) * self.fee_rate\n",
    "        self.balance -= fee\n",
    "        self.realized_pnl -= fee\n",
    "\n",
    "    def _open_position(self, action_val: float, price: float):\n",
    "        notional = self.balance * abs(action_val) * self.leverage_setting\n",
    "        qty = notional / price\n",
    "        self.position_size = qty if action_val > 0 else -qty\n",
    "        self.entry_price = price\n",
    "        margin = notional / self.leverage_setting\n",
    "        self.balance -= margin\n",
    "        self._apply_fee(notional)\n",
    "\n",
    "    def _add_position(self, action_val: float, price: float):\n",
    "        notional = self.balance * abs(action_val) * self.leverage_setting\n",
    "        add_qty = notional / price\n",
    "        total_notional = abs(self.position_size) * self.entry_price + notional\n",
    "        new_size = self.position_size + (add_qty if action_val > 0 else -add_qty)\n",
    "        self.entry_price = total_notional / abs(new_size)\n",
    "        self.position_size = new_size\n",
    "        self.balance -= notional / self.leverage_setting\n",
    "        self._apply_fee(notional)\n",
    "\n",
    "    def _reduce_or_close(self, action_val: float, price: float):\n",
    "        \"\"\"\n",
    "        1. è®¡ç®—ç›®æ ‡ notional = å¯ç”¨ä½™é¢ * |action_val| * æ æ†\n",
    "        2. å¦‚æœç›®æ ‡ notional å°äºå½“å‰æŒä»“ notionalï¼Œåˆ™æŒ‰æ¯”ä¾‹å¹³ä»“\n",
    "        3. å¦‚æœç›®æ ‡ notional >= å½“å‰æŒä»“ notionalï¼Œåˆ™å…ˆå…¨å¹³å†æŒ‰å‰©ä½™ notional åå‘å¼€ä»“\n",
    "        \"\"\"\n",
    "        # ç›®æ ‡ notionalï¼ˆUSDï¼‰\n",
    "        notional_to_close = self.balance * abs(action_val) * self.leverage_setting\n",
    "        # å½“å‰æŒä»“ notionalï¼ˆUSDï¼‰\n",
    "        current_notional = abs(self.position_size) * price\n",
    "\n",
    "        # éƒ¨åˆ†å¹³ä»“\n",
    "        if notional_to_close < current_notional:\n",
    "            # è®¡ç®—éœ€å¹³ä»“æ•°é‡ï¼ˆBTCï¼‰\n",
    "            close_qty = (notional_to_close / price)\n",
    "\n",
    "            # ç»“ç®— PnL\n",
    "            pnl = close_qty * (price - self.entry_price) * (1 if self.position_size > 0 else -1)\n",
    "            self.realized_pnl += pnl\n",
    "\n",
    "            # é€€å›ä¿è¯é‡‘ + ç›ˆäº\n",
    "            self.balance += close_qty * self.entry_price / self.leverage_setting + pnl\n",
    "            self._apply_fee(notional_to_close)\n",
    "\n",
    "            # æ›´æ–°å‰©ä½™ä»“ä½\n",
    "            remain_qty = abs(self.position_size) - close_qty\n",
    "            if remain_qty <= 0:\n",
    "                self.position_size = 0.0\n",
    "                self.entry_price = 0.0\n",
    "            else:\n",
    "                self.position_size = math.copysign(remain_qty, self.position_size)\n",
    "\n",
    "        # å…¨å¹³å¹¶åå‘å¼€ä»“\n",
    "        else:\n",
    "            # --- 1) å¹³æ‰æ‰€æœ‰ç°æœ‰ä»“ä½ ---\n",
    "            # æ—¢æœ‰ notional = current_notional\n",
    "            pnl = abs(self.position_size) * (price - self.entry_price) * (1 if self.position_size > 0 else -1)\n",
    "            self.realized_pnl += pnl\n",
    "            initial_margin = abs(self.position_size) * self.entry_price / self.leverage_setting\n",
    "            self.balance += initial_margin + pnl\n",
    "            self._apply_fee(current_notional)\n",
    " \n",
    "            # æ¸…ç©ºä»“ä½\n",
    "            self.position_size = 0.0\n",
    "            self.entry_price = 0.0\n",
    "\n",
    "            # --- 2) å‰©ä½™ notional ç”¨äºåå‘å¼€ä»“ ---\n",
    "            reverse_notional = self.balance * abs(action_val) * self.leverage_setting\n",
    "            if reverse_notional > 0:\n",
    "                qty = reverse_notional / price\n",
    "                self.position_size = qty if action_val > 0 else -qty\n",
    "                self.entry_price = price\n",
    "                self.balance -= reverse_notional / self.leverage_setting\n",
    "                self._apply_fee(reverse_notional)\n",
    "\n",
    "    def _apply_funding(self, price: float):\n",
    "        \"\"\"æŒ‰åˆ†é’Ÿçº¿æ€§æ’å€¼èµ„é‡‘è´¹ï¼Œæ”¶å–åˆ°/ä»˜å‡º Equity\"\"\"\n",
    "        current_funding = self._current_funding()\n",
    "        notional = abs(self.position_size) * price\n",
    "        funding_payment = notional * current_funding / (8 * 60)  # æ¯åˆ†é’Ÿä»½é¢\n",
    "        # long æ”¯ä»˜æ­£ fundingï¼Œshort è·å¾—\n",
    "        self.balance -= funding_payment * np.sign(self.position_size)\n",
    "        self.realized_pnl -= funding_payment * np.sign(self.position_size)\n",
    "\n",
    "    def _unrealized_pnl(self, price: float) -> float:\n",
    "        return abs(self.position_size) * (price - self.entry_price) * (\n",
    "            1 if self.position_size > 0 else -1\n",
    "        )\n",
    "\n",
    "    def _check_liquidation(self, price: float):\n",
    "        if self.position_size == 0:\n",
    "            return\n",
    "        notional = abs(self.position_size) * price\n",
    "        equity = self.balance + self._unrealized_pnl(price)\n",
    "        # ç»´æŠ¤ä¿è¯é‡‘æŒ‰åä¹‰ä»·å€¼æ¯”ä¾‹è®¡ç®—\n",
    "        if equity < notional * self.maintenance_margin_ratio:\n",
    "            # å¼ºå¹³ï¼šæŸå¤±æ‰€æœ‰ä¿è¯é‡‘\n",
    "            self.realized_pnl -= notional / self.leverage_setting\n",
    "            self.balance = equity\n",
    "            self.position_size = 0.0\n",
    "            self.entry_price = 0.0\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Observation & Helpers\n",
    "    # ---------------------------------\n",
    "    def _current_price(self) -> float:\n",
    "        return float(self.ohlcv.iloc[self._ptr][\"close\"])\n",
    "\n",
    "    def _current_funding(self) -> float:\n",
    "        return float(self.funding_rate.iloc[self._ptr])\n",
    "\n",
    "    def _current_long_short_ratio(self) -> float:\n",
    "        prev_val = self.long_short_ratio.iloc[self._ptr - 1]\n",
    "        next_val = self.long_short_ratio.iloc[self._ptr]\n",
    "        return float(self.np_random.uniform(min(prev_val, next_val), max(prev_val, next_val)))\n",
    "\n",
    "    def _get_observation(self) -> np.ndarray:\n",
    "        start = self._ptr - self.window_size\n",
    "        tech_np = self.tech_all[start:self._ptr].flatten()\n",
    "        price = float(self.ohlcv.iloc[self._ptr]['close'])\n",
    "        pos_dir = 0.0 if self.position_size == 0 else math.copysign(1, self.position_size)\n",
    "\n",
    "        account_state = np.array([\n",
    "            self.balance,\n",
    "            self.position_size,\n",
    "            self.entry_price,\n",
    "            pos_dir,\n",
    "            self._unrealized_pnl(price)\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        obs = np.concatenate([\n",
    "            tech_np,\n",
    "            account_state,\n",
    "            np.array([\n",
    "                float(self.funding_rate.iloc[self._ptr]),\n",
    "                self._current_long_short_ratio()\n",
    "            ], dtype=np.float32)\n",
    "        ])\n",
    "\n",
    "        if np.any(np.isnan(obs)) or np.any(np.isinf(obs)):\n",
    "            raise ValueError(\"Observation contains inf or nan!\")\n",
    "        return obs\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Render / Close\n",
    "    # ---------------------------------\n",
    "    def render(self):\n",
    "        price = self._current_price()\n",
    "        print(\n",
    "            f\"t={self._ptr} | price={price:.2f} | bal={self.balance:.2f} | pos={self.position_size:.4f} @ {self.entry_price:.2f} | unreal={self._unrealized_pnl(price):+.2f}\"\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1.  Hyperâ€‘parameters & helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "TOTAL_TIMESTEPS  = 50_000_000          # â‡¦ reduce for a faster test\n",
    "ROLLOUT_STEPS    = 16384               # rollout length per update\n",
    "N_EPOCHS         = 10                  # PPO optimisation epochs per update\n",
    "GAMMA            = 0.999               # discount factor (bitcoin dataset is 1â€‘min bars)\n",
    "GAE_LAMBDA       = 0.95                # GAE parameter Î»\n",
    "CLIP_RANGE       = 0.2\n",
    "ENT_COEF         = 0.00\n",
    "VF_COEF          = 0.5\n",
    "MAX_GRAD_NORM    = 0.5\n",
    "LEARNING_RATE    = 3e-4\n",
    "TENSORBOARD_DIR  = \"runs/ppo_bitcoin\"\n",
    "N_ENVS           = 80                  # number of parallel environments\n",
    "\n",
    "# ---- early stopping ----\n",
    "EVAL_FREQ                 = 50000          # env steps between evaluations\n",
    "MAX_NO_IMPROVEMENT_EVALS  = 50             # patience: 50 consecutive evals\n",
    "MIN_EVALS_BEFORE_STOP     = 50             # burnâ€‘in (same as patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2.  Vectorised environment with reward logging\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def make_env() -> BitcoinFuturesEnv:  # type: ignore[name-defined]\n",
    "    return BitcoinFuturesEnv(\n",
    "            ohlcv_df,\n",
    "            ls_series,\n",
    "            funding_series,\n",
    "            random_start=True,\n",
    "            leverage=1\n",
    "        )\n",
    "\n",
    "train_env = VecMonitor(SubprocVecEnv([make_env for _ in range(N_ENVS)]))\n",
    "eval_env  = VecMonitor(DummyVecEnv([make_env]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3. PPO agent â€“ simple MLP policy\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "best_model_path = Path(\"./ppo_ckpts/best_model.zip\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(\"âœ… Found previous best model â€“ resuming training from it.\")\n",
    "    model = PPO.load(\n",
    "        best_model_path,\n",
    "        env=train_env,\n",
    "        tensorboard_log=TENSORBOARD_DIR,\n",
    "        # device=\"cpu\",\n",
    "    )\n",
    "else:\n",
    "    print(\"ğŸš€ No previous model found â€“ starting fresh training.\")\n",
    "    policy_kwargs = dict(\n",
    "        net_arch=dict(\n",
    "            pi=[256, 64],\n",
    "            vf=[256, 64]\n",
    "        ),\n",
    "        activation_fn=torch.nn.SiLU,        # swish-like activation (better for value flow)\n",
    "        ortho_init=True,\n",
    "        log_std_init=-0.5,\n",
    "    )\n",
    "\n",
    "    model = PPO(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_env,\n",
    "        n_steps=ROLLOUT_STEPS,\n",
    "        batch_size=64,\n",
    "        n_epochs=N_EPOCHS,\n",
    "        gamma=GAMMA,\n",
    "        gae_lambda=GAE_LAMBDA,\n",
    "        clip_range=CLIP_RANGE,\n",
    "        ent_coef=ENT_COEF,\n",
    "        vf_coef=VF_COEF,\n",
    "        max_grad_norm=MAX_GRAD_NORM,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        tensorboard_log=TENSORBOARD_DIR,\n",
    "        verbose=1,\n",
    "        # device=\"cpu\",\n",
    "        # policy_kwargs=policy_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20956e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4. Earlyâ€‘stopping evaluation callback (no periodic checkpoints)\n",
    "# ---------------------------------------------------------------------------\n",
    "stop_callback = StopTrainingOnNoModelImprovement(\n",
    "    max_no_improvement_evals=MAX_NO_IMPROVEMENT_EVALS,\n",
    "    min_evals=MIN_EVALS_BEFORE_STOP,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    eval_freq=max(EVAL_FREQ // N_ENVS, 100),\n",
    "    best_model_save_path=\"./ppo_ckpts\",  # only best model is saved\n",
    "    log_path=\"./ppo_eval_logs\",\n",
    "    deterministic=False,\n",
    "    render=False,\n",
    "    callback_after_eval=stop_callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 5. Training (progress bar & early stop)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\nâ–¶ï¸  Start PPO training â€“ early stopping (patience 50) â€¦\\n\")\n",
    "model.learn(\n",
    "    total_timesteps=TOTAL_TIMESTEPS,\n",
    "    callback=eval_callback,\n",
    "    progress_bar=True,\n",
    ")\n",
    "model.save(\"ppo_bitcoin_final\")\n",
    "print(\"\\nâœ“ Training finished (steps exhausted or earlyâ€‘stopped). Model saved as `ppo_bitcoin_final.zip`.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 6. Backâ€‘test on full history (no random start)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def backtest_ppo(env: BitcoinFuturesEnv, agent: PPO) -> Dict[str, Any]:  # type: ignore[name-defined]\n",
    "    obs, _ = env.reset(seed=0)\n",
    "    equity_curve = [env.balance]\n",
    "    trade_profits = []\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        equity_curve.append(info[\"equity\"])\n",
    "        if reward != 0.0:\n",
    "            trade_profits.append(reward)\n",
    "\n",
    "    equity_series = pd.Series(equity_curve)\n",
    "    init_eq, final_eq = equity_series.iloc[0], equity_series.iloc[-1]\n",
    "    total_return = (final_eq - init_eq) / init_eq\n",
    "\n",
    "    mins_per_year = 365 * 24 * 60\n",
    "    annual_ret = (1 + total_return) ** (mins_per_year / len(equity_series)) - 1\n",
    "\n",
    "    ret_series = equity_series.pct_change().fillna(0)\n",
    "    sharpe = np.sqrt(mins_per_year) * ret_series.mean() / (ret_series.std() + 1e-12)\n",
    "\n",
    "    profits = np.sum([p for p in trade_profits if p > 0])\n",
    "    losses  = -np.sum([p for p in trade_profits if p < 0])\n",
    "    win_rate = np.mean(np.array(trade_profits) > 0) if trade_profits else 0.0\n",
    "    profit_factor = profits / losses if losses > 0 else float(\"inf\")\n",
    "\n",
    "    drawdown = (equity_series - equity_series.cummax()) / equity_series.cummax()\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    return {\n",
    "        \"total_return\":       total_return,\n",
    "        \"annualized_return\":  annual_ret,\n",
    "        \"win_rate\":           win_rate,\n",
    "        \"profit_factor\":      profit_factor,\n",
    "        \"max_drawdown\":       max_dd,\n",
    "        \"sharpe_ratio\":       sharpe,\n",
    "        \"n_trades\":           len(trade_profits),\n",
    "        \"n_steps\":            len(equity_series) - 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff947f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â–¶ï¸  Running backâ€‘test â€¦\")\n",
    "\n",
    "env_eval = BitcoinFuturesEnv(\n",
    "    ohlcv_df,\n",
    "    ls_series,\n",
    "    funding_series,\n",
    "    random_start=False,\n",
    ")\n",
    "metrics = backtest_ppo(env_eval, model)\n",
    "\n",
    "env_eval.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===========  Backâ€‘test metrics  ===========\")\n",
    "for k, v in metrics.items():\n",
    "    if k in {\"win_rate\", \"sharpe_ratio\"}:\n",
    "        print(f\"{k:18s}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:18s}: {v:.4%}\")\n",
    "print(\"===========================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
