{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98aaa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method(\"forkserver\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0b80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from typing import Any, Dict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pybit.unified_trading import HTTP\n",
    "from IPython.display import display\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecMonitor, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import (\n",
    "    EvalCallback,\n",
    "    StopTrainingOnNoModelImprovement,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40929d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _datetime_to_ms(dt: str | datetime) -> int:\n",
    "    ts = pd.Timestamp(dt, tz=\"UTC\") if isinstance(dt, str) else pd.Timestamp(dt).tz_convert(\"UTC\")\n",
    "    return int(ts.timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3089111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_ohlcv_minute(session: HTTP, symbol: str, start_ms: int, end_ms: int, limit: int = 1000) -> pd.DataFrame:\n",
    "    rows: list[list] = []\n",
    "    cur = start_ms\n",
    "    step_ms = 60_000 # 1 minute in milliseconds\n",
    "    total_minutes = (end_ms - start_ms) // step_ms\n",
    "\n",
    "    with tqdm(total=total_minutes, desc=f\"Fetching {symbol} OHLCV\") as pbar:\n",
    "        while cur < end_ms:\n",
    "            start_time_current_call = cur\n",
    "            resp = session.get_kline(category=\"linear\", symbol=symbol, interval=\"1\", start=cur, limit=limit)\n",
    "            data = resp[\"result\"][\"list\"]\n",
    "            if not data:\n",
    "                # If no data is returned, assume we reached the end for the requested period\n",
    "                # Update progress bar to reflect the remaining time as processed\n",
    "                remaining_minutes = (end_ms - cur) // step_ms\n",
    "                pbar.update(remaining_minutes)\n",
    "                break\n",
    "\n",
    "            rows.extend(data)\n",
    "            last_ts = int(data[-1][0])\n",
    "\n",
    "            # Calculate minutes fetched in this call and update progress bar\n",
    "            minutes_fetched = (last_ts - start_time_current_call + step_ms) // step_ms\n",
    "            pbar.update(minutes_fetched)\n",
    "\n",
    "            # Set cursor for the next iteration\n",
    "            cur = last_ts + step_ms\n",
    "\n",
    "            # Ensure progress doesn't exceed total if API returns data beyond end_ms\n",
    "            if pbar.n > total_minutes:\n",
    "                 pbar.n = total_minutes\n",
    "                 pbar.refresh()\n",
    "\n",
    "        # Ensure the progress bar completes if the loop finishes early\n",
    "        if pbar.n < total_minutes:\n",
    "             pbar.update(total_minutes - pbar.n)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"startTime\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"turnover\"])\n",
    "    df[\"startTime\"] = pd.to_datetime(df[\"startTime\"], unit=\"ms\", utc=True)\n",
    "    df.set_index(\"startTime\", inplace=True)\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms)\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "    df = df.astype(float)[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec2423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_long_short_ratio(session: HTTP, symbol: str, start_ms: int, end_ms: int) -> pd.Series:\n",
    "    rows = []\n",
    "    limit = 500\n",
    "    interval_ms = 5 * 60_000 # 5 minutes in milliseconds\n",
    "    total_intervals = (end_ms - start_ms) // interval_ms\n",
    "    last_fetched_ts = start_ms\n",
    "\n",
    "    with tqdm(total=total_intervals, desc=f\"Fetching {symbol} Long/Short Ratio\") as pbar:\n",
    "        while True:\n",
    "            start_time_current_call = last_fetched_ts\n",
    "            try:\n",
    "                resp = session.get_long_short_ratio(\n",
    "                    category=\"linear\",\n",
    "                    symbol=symbol,\n",
    "                    period=\"5min\",\n",
    "                    startTime=start_time_current_call, # Use last fetched timestamp to avoid overlap issues\n",
    "                    endTime=end_ms,\n",
    "                    limit=limit\n",
    "                )\n",
    "                data = resp[\"result\"][\"list\"]\n",
    "                if not data:\n",
    "                    # No more data in the range for this call\n",
    "                    remaining_intervals = max(0, (end_ms - last_fetched_ts) // interval_ms)\n",
    "                    pbar.update(remaining_intervals)\n",
    "                    break # Exit loop if no data is returned\n",
    "\n",
    "                rows.extend(data)\n",
    "                current_last_ts = int(data[-1][\"timestamp\"])\n",
    "\n",
    "                # Calculate intervals fetched based on time covered\n",
    "                intervals_fetched = max(0, (current_last_ts - last_fetched_ts) // interval_ms)\n",
    "                # Add 1 interval for the last timestamp itself if it wasn't fully covered by the division\n",
    "                if (current_last_ts - last_fetched_ts) % interval_ms > 0 or intervals_fetched == 0:\n",
    "                     intervals_fetched += 1\n",
    "\n",
    "\n",
    "                pbar.update(intervals_fetched)\n",
    "                last_fetched_ts = current_last_ts + interval_ms # Set start for next potential fetch\n",
    "\n",
    "                # Check if we have fetched data beyond the requested end_ms\n",
    "                if last_fetched_ts >= end_ms:\n",
    "                     # Ensure progress bar completes if we fetched up to or beyond end_ms\n",
    "                     if pbar.n < total_intervals:\n",
    "                         pbar.update(total_intervals - pbar.n)\n",
    "                     break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                # Update progress bar to reflect the assumed end if an error occurs\n",
    "                if pbar.n < total_intervals:\n",
    "                    pbar.update(total_intervals - pbar.n)\n",
    "                break # Exit loop on error\n",
    "\n",
    "        # Ensure the progress bar completes fully if the loop finishes early\n",
    "        if pbar.n < total_intervals:\n",
    "             pbar.update(total_intervals - pbar.n)\n",
    "\n",
    "\n",
    "    if not rows:\n",
    "        # Return an empty series with the correct dtype if no data was fetched\n",
    "        return pd.Series(dtype=float, name=\"ls_ratio\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"].astype(int), unit=\"ms\", utc=True)\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "    df = df.sort_index()\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms)\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "    # Remove potential duplicates from overlapping API calls if cursor wasn't effective\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name=\"ls_ratio\")\n",
    "\n",
    "    df[[\"buyRatio\", \"sellRatio\"]] = df[[\"buyRatio\", \"sellRatio\"]].astype(float)\n",
    "    # Avoid division by zero if both buyRatio and sellRatio are 0\n",
    "    total_ratio = df[\"buyRatio\"] + df[\"sellRatio\"]\n",
    "    ls_ratio = df[\"buyRatio\"].divide(total_ratio).fillna(0.5) # Fill NaN with 0.5 (neutral) or 0\n",
    "\n",
    "    # Resample to 1 minute and forward fill\n",
    "    ls_ratio = ls_ratio.resample(\"1min\").ffill()\n",
    "    # Ensure the resampled series covers the full requested range, padding with ffill/bfill\n",
    "    full_range_index = pd.date_range(start=pd.to_datetime(start_ms, unit='ms', utc=True),\n",
    "                                     end=pd.to_datetime(end_ms - 1, unit='ms', utc=True), # end is exclusive\n",
    "                                     freq='1min')\n",
    "    ls_ratio = ls_ratio.reindex(full_range_index).ffill().bfill() # Forward fill then backfill NaNs\n",
    "\n",
    "    return ls_ratio.rename(\"ls_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60251003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_funding_rate(session: HTTP, symbol: str, start_ms: int, end_ms: int) -> pd.Series:\n",
    "    rows = []\n",
    "    cursor = None\n",
    "    limit = 200 # Max limit for funding rate history\n",
    "    # Estimate total intervals for progress bar (funding typically every 8 hours)\n",
    "    interval_ms = 8 * 60 * 60_000\n",
    "    total_intervals = max(1, (end_ms - start_ms) // interval_ms)\n",
    "    last_fetched_ts = start_ms # Track the timestamp of the last fetched record for progress update\n",
    "\n",
    "    with tqdm(total=total_intervals, desc=f\"Fetching {symbol} Funding Rate\") as pbar:\n",
    "        while True:\n",
    "            try:\n",
    "                resp = session.get_funding_rate_history(\n",
    "                    category=\"linear\",\n",
    "                    symbol=symbol,\n",
    "                    # Rely primarily on cursor for pagination, filter by time later\n",
    "                    limit=limit,\n",
    "                    cursor=cursor\n",
    "                )\n",
    "\n",
    "                data = resp[\"result\"][\"list\"]\n",
    "                if not data:\n",
    "                    # No more data from API for this cursor\n",
    "                    if pbar.n < total_intervals:\n",
    "                        pbar.update(total_intervals - pbar.n) # Complete the bar\n",
    "                    break\n",
    "\n",
    "                rows.extend(data)\n",
    "                current_last_ts = int(data[-1][\"fundingRateTimestamp\"])\n",
    "\n",
    "                # Update progress based on time covered since last fetch\n",
    "                if current_last_ts > last_fetched_ts:\n",
    "                    intervals_covered = (current_last_ts - last_fetched_ts) // interval_ms\n",
    "                    # Ensure at least 1 interval is credited if any time passed and data received\n",
    "                    if intervals_covered == 0 and current_last_ts > last_fetched_ts:\n",
    "                         intervals_covered = 1\n",
    "                    # Cap update to not exceed total\n",
    "                    update_amount = min(intervals_covered, total_intervals - pbar.n)\n",
    "                    if update_amount > 0:\n",
    "                        pbar.update(update_amount)\n",
    "                    last_fetched_ts = current_last_ts # Update last fetched timestamp\n",
    "\n",
    "                cursor = resp[\"result\"].get(\"nextPageCursor\")\n",
    "                if not cursor:\n",
    "                    # No next page cursor means we are done fetching\n",
    "                    if pbar.n < total_intervals:\n",
    "                        pbar.update(total_intervals - pbar.n) # Complete the bar\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during funding rate fetch: {e}\")\n",
    "                # Update progress bar to reflect the assumed end if an error occurs\n",
    "                if pbar.n < total_intervals:\n",
    "                    pbar.update(total_intervals - pbar.n)\n",
    "                break # Exit loop on error\n",
    "\n",
    "        # Ensure the progress bar completes fully if the loop finished early\n",
    "        if pbar.n < total_intervals:\n",
    "             pbar.update(total_intervals - pbar.n)\n",
    "\n",
    "    if not rows:\n",
    "        # Return an empty series with the correct dtype and name if no data was fetched\n",
    "        return pd.Series(dtype=float, name=\"fundingRate\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"fundingRateTimestamp\"] = pd.to_datetime(df[\"fundingRateTimestamp\"].astype(int), unit=\"ms\", utc=True)\n",
    "    df.set_index(\"fundingRateTimestamp\", inplace=True)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Filter data strictly within the requested range [start_ms, end_ms) AFTER collecting all data\n",
    "    df = df[(df.index >= pd.to_datetime(start_ms, unit='ms', utc=True)) & (df.index < pd.to_datetime(end_ms, unit='ms', utc=True))]\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name=\"fundingRate\")\n",
    "\n",
    "    # Remove potential duplicates just in case (e.g., overlapping calls if cursor logic had issues)\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    df[\"fundingRate\"] = df[\"fundingRate\"].astype(float)\n",
    "\n",
    "    # Resample to 1 minute and interpolate linearly\n",
    "    funding_series = df[\"fundingRate\"].resample(\"1min\").interpolate(method='linear')\n",
    "\n",
    "    # Ensure the resampled series covers the full requested range, padding with ffill/bfill\n",
    "    full_range_index = pd.date_range(start=pd.to_datetime(start_ms, unit='ms', utc=True),\n",
    "                                     end=pd.to_datetime(end_ms - 1, unit='ms', utc=True), # end is exclusive\n",
    "                                     freq='1min')\n",
    "    # Reindex to the full range, then fill any remaining NaNs at the beginning/end\n",
    "    # Interpolation handles NaNs between points, ffill/bfill handle edges.\n",
    "    funding_series = funding_series.reindex(full_range_index).ffill().bfill()\n",
    "\n",
    "    return funding_series.rename(\"fundingRate\") # Ensure series name is set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5a5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bybit_data(\n",
    "    symbol: str = \"BTCUSDT\",\n",
    "    start: str | datetime = \"2025-03-01 00:00:00\",\n",
    "    end: str | datetime = \"2025-04-01 00:00:00\",\n",
    "    save_csv: bool = False,\n",
    "    out_dir: str | Path = \"data\",\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    import numpy as np\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    npz_path = out / f\"{symbol}_bybit_data.npz\"\n",
    "\n",
    "    # ---------- Try loading from .npz ----------\n",
    "    if npz_path.exists():\n",
    "        print(f\"Loading data from NPZ file: {npz_path}\")\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "\n",
    "        ohlcv_cols = data[\"ohlcv_columns\"]\n",
    "        ohlcv_idx = pd.to_datetime(data[\"ohlcv_index\"])\n",
    "        ohlcv = pd.DataFrame(data[\"ohlcv_values\"], columns=ohlcv_cols)\n",
    "        ohlcv.index = ohlcv_idx\n",
    "        ohlcv.index.name = \"startTime\"\n",
    "        ohlcv = ohlcv.astype(float).asfreq(\"1min\")\n",
    "\n",
    "        lsr = pd.Series(data[\"lsr_values\"], index=pd.to_datetime(data[\"lsr_index\"]), name=\"ls_ratio\").asfreq(\"1min\")\n",
    "        funding = pd.Series(data[\"funding_values\"], index=pd.to_datetime(data[\"funding_index\"]), name=\"fundingRate\").asfreq(\"1min\")\n",
    "\n",
    "        return ohlcv, lsr, funding\n",
    "\n",
    "    # ---------- Fetch from API ----------\n",
    "    print(\"Fetching data from Bybit API...\")\n",
    "    session = HTTP(testnet=False)\n",
    "    start_ms, end_ms = _datetime_to_ms(start), _datetime_to_ms(end)\n",
    "    ohlcv = _fetch_ohlcv_minute(session, symbol, start_ms, end_ms)\n",
    "    lsr = _fetch_long_short_ratio(session, symbol, start_ms, end_ms)\n",
    "    funding = _fetch_funding_rate(session, symbol, start_ms, end_ms)\n",
    "\n",
    "    # ---------- Save to npz ----------\n",
    "    print(f\"Saving data to NPZ file: {npz_path}\")\n",
    "    np.savez_compressed(\n",
    "        npz_path,\n",
    "        ohlcv_values=ohlcv.to_numpy(),\n",
    "        ohlcv_columns=np.array(ohlcv.columns),\n",
    "        ohlcv_index=ohlcv.index.astype(np.int64),\n",
    "        lsr_values=lsr.to_numpy(),\n",
    "        lsr_index=lsr.index.astype(np.int64),\n",
    "        funding_values=funding.to_numpy(),\n",
    "        funding_index=funding.index.astype(np.int64),\n",
    "    )\n",
    "\n",
    "    # ---------- Optionally save to CSV ----------\n",
    "    if save_csv:\n",
    "        print(f\"Also saving CSV to {out_dir}...\")\n",
    "        ohlcv.to_csv(out / f\"{symbol}_ohlcv_1min.csv\")\n",
    "        lsr.to_csv(out / f\"{symbol}_long_short_ratio.csv\", header=True)\n",
    "        funding.to_csv(out / f\"{symbol}_funding_rate.csv\", header=True)\n",
    "\n",
    "    return ohlcv, lsr, funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69867a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from NPZ file: data/BTCUSDT_bybit_data.npz\n"
     ]
    }
   ],
   "source": [
    "ohlcv_df, ls_series, funding_series = fetch_bybit_data(save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4bba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHLCV Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 44640 entries, 2025-03-01 00:00:00 to 2025-03-31 23:59:00\n",
      "Freq: min\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    44640 non-null  float64\n",
      " 1   high    44640 non-null  float64\n",
      " 2   low     44640 non-null  float64\n",
      " 3   close   44640 non-null  float64\n",
      " 4   volume  44640 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 2.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Long/Short Ratio Data:\n",
      "<class 'pandas.core.series.Series'>\n",
      "DatetimeIndex: 44640 entries, 2025-03-01 00:00:00 to 2025-03-31 23:59:00\n",
      "Freq: min\n",
      "Series name: ls_ratio\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "44640 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 697.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Funding Rate Data:\n",
      "<class 'pandas.core.series.Series'>\n",
      "DatetimeIndex: 44640 entries, 2025-03-01 00:00:00 to 2025-03-31 23:59:00\n",
      "Freq: min\n",
      "Series name: fundingRate\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "44640 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 697.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"OHLCV Data:\")\n",
    "display(ohlcv_df.info())\n",
    "\n",
    "print(\"\\nLong/Short Ratio Data:\")\n",
    "display(ls_series.info())\n",
    "\n",
    "print(\"\\nFunding Rate Data:\")\n",
    "display(funding_series.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c7a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(series: pd.Series, period: int) -> pd.Series:\n",
    "    return series.rolling(window=period, min_periods=period).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a4b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(series: pd.Series, period: int) -> pd.Series:\n",
    "    return series.ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15047e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(df: pd.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:\n",
    "    ema_fast = ema(df[\"close\"], fast)\n",
    "    ema_slow = ema(df[\"close\"], slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = ema(macd_line, signal)\n",
    "    hist = macd_line - signal_line\n",
    "    return pd.DataFrame({\"macd\": macd_line, \"macd_signal\": signal_line, \"macd_hist\": hist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc70fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0.0)).rolling(period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0.0)).rolling(period).mean()\n",
    "    rs = gain / (loss + 1e-12)\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da91f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connors_rsi(df: pd.DataFrame, rsi_period: int = 3, streak_rsi_period: int = 2, pct_rank_period: int = 100) -> pd.Series:\n",
    "    close = df[\"close\"]\n",
    "    # (1) ‰ª∑Ê†º RSI\n",
    "    rsi_cl = rsi(close, rsi_period)\n",
    "    # (2) ËøûÊ∂®/Ë∑åÂ§©Êï∞\n",
    "    streak = np.sign(close.diff()).fillna(0)\n",
    "    streak = streak.groupby((streak != streak.shift()).cumsum()).cumsum()\n",
    "    rsi_streak = rsi(streak, streak_rsi_period)\n",
    "    # (3) ÂΩìÊó•Ê∂®Ë∑åÂπÖÂú®ËøáÂéª n Êó•ÁôæÂàÜ‰Ωç\n",
    "    pct_change = close.pct_change().fillna(0)\n",
    "    pct_rank = pct_change.rolling(pct_rank_period).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100, raw=False)\n",
    "    # CRSI = ‰∏äËø∞‰∏âËÄÖÂπ≥Âùá\n",
    "    crsi = (rsi_cl + rsi_streak + pct_rank) / 3.0\n",
    "    return crsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7abb53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_resistance(df: pd.DataFrame, lookback: int = 60) -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"ËøîÂõû (support, resistance) ÊîØÊíë / ÂéãÂäõ‰Ωç\"\"\"\n",
    "    rolling_low = df[\"low\"].rolling(lookback).min()\n",
    "    rolling_high = df[\"high\"].rolling(lookback).max()\n",
    "    return rolling_low, rolling_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5daff948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitcoinFuturesEnv(gym.Env):\n",
    "    \"\"\"BTC Ê∞∏Áª≠ÂêàÁ∫¶ÁéØÂ¢ÉÔºàÁ∫øÊÄß„ÄÅUSDT ËÆ°‰ª∑Ôºâ\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ohlcv: pd.DataFrame,\n",
    "        long_short_ratio: pd.Series,\n",
    "        funding_rate: pd.Series,\n",
    "        window_size: int = 60,\n",
    "        initial_balance: float = 10_000.0,\n",
    "        fee_rate: float = 0.00044,\n",
    "        leverage: float = 10.0,\n",
    "        maintenance_margin_ratio: float = 0.005,\n",
    "        random_start: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (\n",
    "            ohlcv.index.freq == \"1min\"\n",
    "        ), \"OHLCV ÂøÖÈ°ªÊòØ 1 ÂàÜÈíüÈ¢ëÁéáÁöÑ Pandas DataFrameÔºåindex ‰∏∫ DateTimeIndex(freq='1min')ÔºåÂΩìÂâç‰∏∫ {}\".format(\n",
    "            ohlcv.index.freq\n",
    "        )\n",
    "\n",
    "        self.ohlcv = ohlcv.reset_index(drop=False)\n",
    "        self.long_short_ratio = long_short_ratio.reset_index(drop=True)\n",
    "        self.funding_rate = funding_rate.reset_index(drop=True)\n",
    "        self.window_size = window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.fee_rate = fee_rate\n",
    "        self.leverage_setting = leverage\n",
    "        self.maintenance_margin_ratio = maintenance_margin_ratio\n",
    "        self.random_start = random_start\n",
    "        self.max_episode_minutes = 14 * 24 * 60  # days in minutes\n",
    "        self._step_counter = 0\n",
    "\n",
    "        # ===== Gym spaces =====\n",
    "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        obs_dim = (\n",
    "            window_size * 14  # OHLC + Volume + 9‰∏™ÊäÄÊúØÊåáÊ†á\n",
    "            + 5  # position info & ÂèØÁî®‰ΩôÈ¢ù etc.\n",
    "            + 2  # ËµÑÈáëË¥πÁéáÂíåÂ§öÁ©∫ÊØî‰æã\n",
    "        )\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        # ÂÜÖÈÉ®Áä∂ÊÄÅ\n",
    "        self._reset_account()\n",
    "        self._ptr: int = self.window_size  # Êï∞ÊçÆÊåáÈíà\n",
    "\n",
    "    # ---------------------------------\n",
    "    # ÈáçÁΩÆ / Ê≠•Ëøõ\n",
    "    # ---------------------------------\n",
    "    def reset(self, *, seed: int | None = None):\n",
    "        super().reset(seed=seed)\n",
    "        self._reset_account()\n",
    "        self._step_counter = 0\n",
    "        if self.random_start:\n",
    "            self._ptr = self.np_random.integers(self.window_size, len(self.ohlcv) - 1)\n",
    "        else:\n",
    "            self._ptr = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"ÊâßË°å‰∏ÄÊ≠•Ôºåaction ‚àà [-1,1].\"\"\"\n",
    "        action_val = float(action[0])\n",
    "        reward = 0.0\n",
    "        info = {}\n",
    "        price = self._current_price()\n",
    "\n",
    "        # === ËµÑÈáëË¥πÂ§ÑÁêÜ ===\n",
    "        self._apply_funding(price)\n",
    "\n",
    "        # === Ëß£ÊûêÂä®‰Ωú ===\n",
    "        if abs(action_val) > 1e-2:\n",
    "            if self.position_size == 0:\n",
    "                # ÂºÄÊñ∞‰ªì\n",
    "                self._open_position(action_val, price)\n",
    "            else:\n",
    "                same_direction = (self.position_size > 0 and action_val > 0) or (\n",
    "                    self.position_size < 0 and action_val < 0\n",
    "                )\n",
    "                if same_direction:\n",
    "                    # Âä†‰ªì\n",
    "                    self._add_position(action_val, price)\n",
    "                else:\n",
    "                    # Âáè‰ªìÊàñÂèçÂêë ‚Üí ÂÖàÂπ≥ÈÉ®ÂàÜ / ÂÖ®Âπ≥\n",
    "                    self._reduce_or_close(action_val, price)\n",
    "        else:\n",
    "            # no‚Äëop\n",
    "            pass\n",
    "\n",
    "        # === Âº∫Âπ≥Ê£ÄÊü• ===\n",
    "        self._check_liquidation(price)\n",
    "\n",
    "        # === Êó∂Èó¥ÂêëÂâçÊé®Ëøõ ===\n",
    "        self._ptr += 1\n",
    "        self._step_counter += 1\n",
    "        # Âà∞Êï∞ÊçÆÊú´Â∞æÁÆó‰ΩútruncateÔºàÊó∂Èó¥Áî®Â∞ΩÔºâ\n",
    "        truncated = self._ptr >= len(self.ohlcv) - 1 or self._step_counter >= self.max_episode_minutes\n",
    "        # ‰ΩôÈ¢ù‰∏∫Èõ∂ÊàñË¥üÊï∞ÁÆó‰ΩúterminatedÔºàÁ†¥‰∫ßÔºâ\n",
    "        terminated = self.balance <= 0\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        reward = self.realized_pnl + (self._unrealized_pnl(price) - self._last_unrealized_pnl)  # Â∑ÆÂàÜÂ•ñÂä±\n",
    "        self._last_unrealized_pnl = self._unrealized_pnl(price)\n",
    "        self.realized_pnl = 0.0  # Ê∏ÖÈõ∂ÔºåÈÅøÂÖç‰∏ãËΩÆÈáçÂ§ç\n",
    "\n",
    "        info.update(\n",
    "            {\n",
    "                \"equity\": self.balance + self._unrealized_pnl(price),\n",
    "                \"position_size\": self.position_size,\n",
    "                \"entry_price\": self.entry_price,\n",
    "                \"unrealized_pnl\": self._unrealized_pnl(price),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if terminated:\n",
    "            info[\"termination_reason\"] = \"bankrupt\"\n",
    "        elif truncated:\n",
    "            info[\"termination_reason\"] = \"time_limit\"\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Ë¥¶Êà∑ÈÄªËæë\n",
    "    # ---------------------------------\n",
    "    def _reset_account(self):\n",
    "        self._last_unrealized_pnl = 0.0  # ÂàùÂßãÂåñËøΩË∏™ÊµÆÂä®Êî∂ÁõäÂ∑ÆÂàÜ\n",
    "        self.balance: float = self.initial_balance  # ÂèØÁî®‰ΩôÈ¢ù / Equity\n",
    "        self.position_size: float = 0.0  # >0 long <0 short (Âº†Êï∞ BTC)\n",
    "        self.entry_price: float = 0.0\n",
    "        self.realized_pnl: float = 0.0\n",
    "\n",
    "    def _apply_fee(self, notional: float):\n",
    "        fee = abs(notional) * self.fee_rate\n",
    "        self.balance -= fee\n",
    "        self.realized_pnl -= fee\n",
    "\n",
    "    def _open_position(self, action_val: float, price: float):\n",
    "        notional = self.balance * abs(action_val) * self.leverage_setting\n",
    "        qty = notional / price\n",
    "        self.position_size = qty if action_val > 0 else -qty\n",
    "        self.entry_price = price\n",
    "        margin = notional / self.leverage_setting\n",
    "        self.balance -= margin\n",
    "        self._apply_fee(notional)\n",
    "\n",
    "    def _add_position(self, action_val: float, price: float):\n",
    "        additional_notional = self.balance * abs(action_val) * self.leverage_setting\n",
    "        add_qty = additional_notional / price\n",
    "        new_position_size = self.position_size + (add_qty if action_val > 0 else -add_qty)\n",
    "        # Âä†ÊùÉÂπ≥ÂùáÂºÄ‰ªì‰ª∑\n",
    "        self.entry_price = (\n",
    "            abs(self.position_size) * self.entry_price + additional_notional\n",
    "        ) / abs(new_position_size)\n",
    "        self.position_size = new_position_size\n",
    "        margin = additional_notional / self.leverage_setting\n",
    "        self.balance -= margin\n",
    "        self._apply_fee(additional_notional)\n",
    "\n",
    "    def _reduce_or_close(self, action_val: float, price: float):\n",
    "        # Ëã•ÊñπÂêëÁõ∏ÂèçÔºåÂàôÊåâÊØî‰æãÂπ≥‰ªì\n",
    "        ratio = abs(action_val)\n",
    "        close_qty = abs(self.position_size) * ratio\n",
    "        close_notional = close_qty * price\n",
    "        # Â∑≤Áªì PnL\n",
    "        pnl = close_qty * (price - self.entry_price) * (1 if self.position_size > 0 else -1)\n",
    "        self.realized_pnl += pnl\n",
    "        self.balance += (close_notional / self.leverage_setting) + pnl  # ÈÄÄ‰øùËØÅÈáë + Áõà‰∫è\n",
    "        self._apply_fee(close_notional)\n",
    "        # Êõ¥Êñ∞Ââ©‰Ωô‰ªì‰Ωç\n",
    "        remain_qty = abs(self.position_size) - close_qty\n",
    "        self.position_size = math.copysign(remain_qty, self.position_size) if remain_qty > 0 else 0.0\n",
    "        if self.position_size == 0:\n",
    "            self.entry_price = 0.0\n",
    "\n",
    "    def _apply_funding(self, price: float):\n",
    "        \"\"\"ÊåâÂàÜÈíüÁ∫øÊÄßÊèíÂÄºËµÑÈáëË¥πÔºåÊî∂ÂèñÂà∞/‰ªòÂá∫ Equity\"\"\"\n",
    "        current_funding = self._current_funding()\n",
    "        notional = abs(self.position_size) * price\n",
    "        funding_payment = notional * current_funding / (8 * 60)  # ÊØèÂàÜÈíü‰ªΩÈ¢ù\n",
    "        # long ÊîØ‰ªòÊ≠£ fundingÔºåshort Ëé∑Âæó\n",
    "        self.balance -= funding_payment * np.sign(self.position_size)\n",
    "\n",
    "    def _unrealized_pnl(self, price: float) -> float:\n",
    "        return abs(self.position_size) * (price - self.entry_price) * (\n",
    "            1 if self.position_size > 0 else -1\n",
    "        )\n",
    "\n",
    "    def _check_liquidation(self, price: float):\n",
    "        if self.position_size == 0:\n",
    "            return\n",
    "        notional = abs(self.position_size) * price\n",
    "        margin = notional / self.leverage_setting\n",
    "        equity = self.balance + self._unrealized_pnl(price)\n",
    "        if equity < margin * self.maintenance_margin_ratio:\n",
    "            # Âº∫Âπ≥\n",
    "            self.realized_pnl += -margin  # ÂÖ®ÈÉ®‰øùËØÅÈáë‰∫èÊçü\n",
    "            self.position_size = 0.0\n",
    "            self.entry_price = 0.0\n",
    "            self.balance = equity  # Âº∫Âπ≥Âêé‰ªÖÂâ©‰ΩôÁöÑ equity\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Observation & Helpers\n",
    "    # ---------------------------------\n",
    "    def _current_price(self) -> float:\n",
    "        return float(self.ohlcv.iloc[self._ptr][\"close\"])\n",
    "\n",
    "    def _current_funding(self) -> float:\n",
    "        return float(self.funding_rate.iloc[self._ptr])\n",
    "\n",
    "    def _current_long_short_ratio(self) -> float:\n",
    "        prev_val = self.long_short_ratio.iloc[self._ptr - 1]\n",
    "        next_val = self.long_short_ratio.iloc[self._ptr]\n",
    "        return float(self.np_random.uniform(min(prev_val, next_val), max(prev_val, next_val)))\n",
    "\n",
    "    def _get_observation(self) -> np.ndarray:\n",
    "        start = self._ptr - self.window_size\n",
    "        end = self._ptr\n",
    "        window = self.ohlcv.iloc[start:end]\n",
    "        # ËÆ°ÁÆóÊäÄÊúØÊåáÊ†á\n",
    "        df_ta = window.copy()\n",
    "        df_ta[\"sma_fast\"] = sma(df_ta[\"close\"], 20)\n",
    "        df_ta[\"sma_slow\"] = sma(df_ta[\"close\"], 50)\n",
    "        df_ta[\"ema\"] = ema(df_ta[\"close\"], 20)\n",
    "        macd_df = macd(df_ta)\n",
    "        df_ta = pd.concat([df_ta, macd_df], axis=1)\n",
    "        df_ta[\"crsi\"] = connors_rsi(df_ta)\n",
    "        support, resistance = support_resistance(df_ta)\n",
    "        df_ta[\"support\"] = support\n",
    "        df_ta[\"resistance\"] = resistance\n",
    "\n",
    "        technical = df_ta[[\n",
    "            \"open\",\n",
    "            \"high\",\n",
    "            \"low\",\n",
    "            \"close\",\n",
    "            \"volume\",\n",
    "            \"sma_fast\",\n",
    "            \"sma_slow\",\n",
    "            \"ema\",\n",
    "            \"macd\",\n",
    "            \"macd_signal\",\n",
    "            \"macd_hist\",\n",
    "            \"crsi\",\n",
    "            \"support\",\n",
    "            \"resistance\",\n",
    "        ]].ffill().fillna(0.0)\n",
    "\n",
    "        # Â∞Ü window √ó features ÊãâÂπ≥Êàê‰∏ÄÁª¥\n",
    "        tech_np = technical.to_numpy(dtype=np.float32).flatten()\n",
    "\n",
    "        # Ë¥¶Êà∑Áä∂ÊÄÅ\n",
    "        price = self._current_price()\n",
    "        pos_dir = 0.0 if self.position_size == 0 else math.copysign(1, self.position_size)\n",
    "        account_state = np.array([\n",
    "            self.balance,\n",
    "            self.position_size,\n",
    "            self.entry_price,\n",
    "            pos_dir,\n",
    "            self._unrealized_pnl(price),\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        obs = np.concatenate([\n",
    "            tech_np,\n",
    "            account_state,\n",
    "            np.array([\n",
    "                self._current_funding(),\n",
    "                self._current_long_short_ratio(),\n",
    "            ], dtype=np.float32),\n",
    "        ])\n",
    "\n",
    "        # Ê£ÄÊü• obs ÊòØÂê¶ÂåÖÂê´ inf Êàñ nan\n",
    "        if np.any(np.isinf(obs)) or np.any(np.isnan(obs)):\n",
    "            raise ValueError(\"Observation contains inf or nan!\")\n",
    "        return obs\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Render / Close\n",
    "    # ---------------------------------\n",
    "    def render(self):\n",
    "        price = self._current_price()\n",
    "        print(\n",
    "            f\"t={self._ptr} | price={price:.2f} | bal={self.balance:.2f} | pos={self.position_size:.4f} @ {self.entry_price:.2f} | unreal={self._unrealized_pnl(price):+.2f}\"\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df37d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1.  Hyper‚Äëparameters & helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "TOTAL_TIMESTEPS  = 50_000_000          # ‚á¶ reduce for a faster test\n",
    "ROLLOUT_STEPS    = 8_192               # rollout length per update\n",
    "N_EPOCHS         = 10                  # PPO optimisation epochs per update\n",
    "GAMMA            = 0.999               # discount factor (bitcoin dataset is 1‚Äëmin bars)\n",
    "GAE_LAMBDA       = 0.95                # GAE parameter Œª\n",
    "CLIP_RANGE       = 0.2\n",
    "ENT_COEF         = 0.00\n",
    "VF_COEF          = 0.5\n",
    "MAX_GRAD_NORM    = 0.5\n",
    "LEARNING_RATE    = 3e-4\n",
    "TENSORBOARD_DIR  = \"runs/ppo_bitcoin\"\n",
    "N_ENVS           = 80                  # number of parallel environments\n",
    "\n",
    "# ---- early stopping ----\n",
    "EVAL_FREQ                 = 50000          # env steps between evaluations\n",
    "MAX_NO_IMPROVEMENT_EVALS  = 50             # patience: 50 consecutive evals\n",
    "MIN_EVALS_BEFORE_STOP     = 50             # burn‚Äëin (same as patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2.  Vectorised environment with reward logging\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def make_env() -> BitcoinFuturesEnv:  # type: ignore[name-defined]\n",
    "    return BitcoinFuturesEnv(\n",
    "            ohlcv_df,\n",
    "            ls_series,\n",
    "            funding_series,\n",
    "            random_start=True,\n",
    "        )\n",
    "\n",
    "train_env = VecMonitor(SubprocVecEnv([make_env for _ in range(N_ENVS)]))\n",
    "eval_env  = VecMonitor(SubprocVecEnv([make_env]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3. PPO agent ‚Äì simple MLP policy\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "best_model_path = Path(\"./ppo_ckpts/best_model.zip\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(\"‚úÖ Found previous best model ‚Äì resuming training from it.\")\n",
    "    model = PPO.load(\n",
    "        best_model_path,\n",
    "        env=train_env,\n",
    "        tensorboard_log=TENSORBOARD_DIR,\n",
    "        # device=\"cpu\",\n",
    "    )\n",
    "else:\n",
    "    print(\"üöÄ No previous model found ‚Äì starting fresh training.\")\n",
    "    policy_kwargs = dict(\n",
    "        net_arch=dict(\n",
    "            pi=[512, 256, 64],\n",
    "            vf=[512, 256, 64]\n",
    "        ),\n",
    "        activation_fn=torch.nn.SiLU,        # swish-like activation (better for value flow)\n",
    "        ortho_init=True,\n",
    "        log_std_init=0.5,\n",
    "    )\n",
    "\n",
    "    model = PPO(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_env,\n",
    "        n_steps=ROLLOUT_STEPS,\n",
    "        batch_size=64,\n",
    "        n_epochs=N_EPOCHS,\n",
    "        gamma=GAMMA,\n",
    "        gae_lambda=GAE_LAMBDA,\n",
    "        clip_range=CLIP_RANGE,\n",
    "        ent_coef=ENT_COEF,\n",
    "        vf_coef=VF_COEF,\n",
    "        max_grad_norm=MAX_GRAD_NORM,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        tensorboard_log=TENSORBOARD_DIR,\n",
    "        verbose=1,\n",
    "        # device=\"cpu\",\n",
    "        policy_kwargs=policy_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20956e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4. Early‚Äëstopping evaluation callback (no periodic checkpoints)\n",
    "# ---------------------------------------------------------------------------\n",
    "stop_callback = StopTrainingOnNoModelImprovement(\n",
    "    max_no_improvement_evals=MAX_NO_IMPROVEMENT_EVALS,\n",
    "    min_evals=MIN_EVALS_BEFORE_STOP,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    eval_freq=max(EVAL_FREQ // N_ENVS, 100),\n",
    "    best_model_save_path=\"./ppo_ckpts\",  # only best model is saved\n",
    "    log_path=\"./ppo_eval_logs\",\n",
    "    deterministic=False,\n",
    "    render=False,\n",
    "    callback_after_eval=stop_callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 5. Training (progress bar & early stop)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n‚ñ∂Ô∏è  Start PPO training ‚Äì early stopping (patience 50) ‚Ä¶\\n\")\n",
    "model.learn(\n",
    "    total_timesteps=TOTAL_TIMESTEPS,\n",
    "    callback=eval_callback,\n",
    "    progress_bar=True,\n",
    ")\n",
    "model.save(\"ppo_bitcoin_final\")\n",
    "print(\"\\n‚úì Training finished (steps exhausted or early‚Äëstopped). Model saved as `ppo_bitcoin_final.zip`.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 6. Back‚Äëtest on full history (no random start)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def backtest_ppo(env: BitcoinFuturesEnv, agent: PPO) -> Dict[str, Any]:  # type: ignore[name-defined]\n",
    "    obs, _ = env.reset(seed=0)\n",
    "    equity_curve = [env.balance]\n",
    "    trade_profits = []\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        equity_curve.append(info[\"equity\"])\n",
    "        if reward != 0.0:\n",
    "            trade_profits.append(reward)\n",
    "\n",
    "    equity_series = pd.Series(equity_curve)\n",
    "    init_eq, final_eq = equity_series.iloc[0], equity_series.iloc[-1]\n",
    "    total_return = (final_eq - init_eq) / init_eq\n",
    "\n",
    "    mins_per_year = 365 * 24 * 60\n",
    "    annual_ret = (1 + total_return) ** (mins_per_year / len(equity_series)) - 1\n",
    "\n",
    "    ret_series = equity_series.pct_change().fillna(0)\n",
    "    sharpe = np.sqrt(mins_per_year) * ret_series.mean() / (ret_series.std() + 1e-12)\n",
    "\n",
    "    profits = np.sum([p for p in trade_profits if p > 0])\n",
    "    losses  = -np.sum([p for p in trade_profits if p < 0])\n",
    "    win_rate = np.mean(np.array(trade_profits) > 0) if trade_profits else 0.0\n",
    "    profit_factor = profits / losses if losses > 0 else float(\"inf\")\n",
    "\n",
    "    drawdown = (equity_series - equity_series.cummax()) / equity_series.cummax()\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    return {\n",
    "        \"total_return\":       total_return,\n",
    "        \"annualized_return\":  annual_ret,\n",
    "        \"win_rate\":           win_rate,\n",
    "        \"profit_factor\":      profit_factor,\n",
    "        \"max_drawdown\":       max_dd,\n",
    "        \"sharpe_ratio\":       sharpe,\n",
    "        \"n_trades\":           len(trade_profits),\n",
    "        \"n_steps\":            len(equity_series) - 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff947f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ñ∂Ô∏è  Running back‚Äëtest ‚Ä¶\")\n",
    "\n",
    "env_eval = BitcoinFuturesEnv(\n",
    "    ohlcv_df,\n",
    "    ls_series,\n",
    "    funding_series,\n",
    "    random_start=False,\n",
    ")\n",
    "metrics = backtest_ppo(env_eval, model)\n",
    "\n",
    "env_eval.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===========  Back‚Äëtest metrics  ===========\")\n",
    "for k, v in metrics.items():\n",
    "    if k in {\"win_rate\", \"sharpe_ratio\"}:\n",
    "        print(f\"{k:18s}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:18s}: {v:.4%}\")\n",
    "print(\"===========================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
